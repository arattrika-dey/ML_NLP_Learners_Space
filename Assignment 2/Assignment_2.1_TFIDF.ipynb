{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee11a66-956f-4a47-860a-ba3dbb71321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Corpus\n",
    "corpus = [\n",
    "    'the sun is a star',\n",
    "    'the moon is a satellite',\n",
    "    'the sun and moon are celestial bodies'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2481bbb-05df-40c5-b624-8381dc66bc59",
   "metadata": {},
   "source": [
    "# Manual TF-IDF implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f16e7e2d-9c2a-4ee1-a3c3-db402c29a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_tfidf(corpus):\n",
    "    # Step 1: Tokenization and create vocabulary\n",
    "    documents = [doc.split() for doc in corpus]\n",
    "    vocabulary = set()\n",
    "    for doc in documents:\n",
    "        vocabulary.update(doc)\n",
    "    vocabulary = sorted(vocabulary)\n",
    "    \n",
    "    # Step 2: Calculate document frequency (DF)\n",
    "    df = defaultdict(int)\n",
    "    for word in vocabulary:\n",
    "        for doc in documents:\n",
    "            if word in doc:\n",
    "                df[word] += 1\n",
    "    \n",
    "    # Step 3: Calculate IDF\n",
    "    N = len(documents)\n",
    "    idf = {}\n",
    "    for word in vocabulary:\n",
    "        idf[word] = math.log((N + 1) / (df[word] + 1)) + 1  # Smoothing\n",
    "    \n",
    "    # Step 4: Calculate TF-IDF\n",
    "    tfidf_vectors = []\n",
    "    for doc in documents:\n",
    "        tf = defaultdict(int)\n",
    "        for word in doc:\n",
    "            tf[word] += 1\n",
    "        \n",
    "        # Normalize TF by document length\n",
    "        doc_len = len(doc)\n",
    "        tf_normalized = {word: count/doc_len for word, count in tf.items()}\n",
    "        \n",
    "        # Calculate TF-IDF for this document\n",
    "        doc_tfidf = {}\n",
    "        for word in vocabulary:\n",
    "            tf_val = tf_normalized.get(word, 0)\n",
    "            doc_tfidf[word] = tf_val * idf[word]\n",
    "        \n",
    "        tfidf_vectors.append(doc_tfidf)\n",
    "    \n",
    "    return vocabulary, tfidf_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fa1ed0-ce73-4932-b754-72382393407d",
   "metadata": {},
   "source": [
    "## Get manual TF-IDF results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64d14d74-c08a-480d-a2f3-987a16f13048",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, manual_results = manual_tfidf(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c56b75a-bc63-49be-ba50-9e1ca77bdbfc",
   "metadata": {},
   "source": [
    "# Scikit-learn CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cd3ee17-3246-4b39-b7d7-f7a12e205d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()\n",
    "count_matrix = count_vec.fit_transform(corpus)\n",
    "count_array = count_matrix.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80863958-a5db-472a-9ff3-621902facb07",
   "metadata": {},
   "source": [
    "## Scikit-learn TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5690be77-1774-4f3c-9531-d914060b471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(norm=None, smooth_idf=True)  # Disable L2 normalization for better comparison\n",
    "tfidf_matrix = tfidf_vec.fit_transform(corpus)\n",
    "tfidf_array = tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a9e821-3747-46c6-8c65-a8ec7e0e6993",
   "metadata": {},
   "source": [
    "# Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcb5c605-aa4b-4b31-949e-e5304d6e6758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['a', 'and', 'are', 'bodies', 'celestial', 'is', 'moon', 'satellite', 'star', 'sun', 'the']\n",
      "\n",
      "Manual TF-IDF results:\n",
      "Document 1:\n",
      "a: 0.2575 | and: 0.0000 | are: 0.0000 | bodies: 0.0000 | celestial: 0.0000 | is: 0.2575 | moon: 0.0000 | satellite: 0.0000 | star: 0.3386 | sun: 0.2575 | the: 0.2000 | \n",
      "Document 2:\n",
      "a: 0.2575 | and: 0.0000 | are: 0.0000 | bodies: 0.0000 | celestial: 0.0000 | is: 0.2575 | moon: 0.2575 | satellite: 0.3386 | star: 0.0000 | sun: 0.0000 | the: 0.2000 | \n",
      "Document 3:\n",
      "a: 0.0000 | and: 0.2419 | are: 0.2419 | bodies: 0.2419 | celestial: 0.2419 | is: 0.0000 | moon: 0.1840 | satellite: 0.0000 | star: 0.0000 | sun: 0.1840 | the: 0.1429 | \n",
      "\n",
      "Scikit-learn CountVectorizer results:\n",
      "['and' 'are' 'bodies' 'celestial' 'is' 'moon' 'satellite' 'star' 'sun'\n",
      " 'the']\n",
      "[[0 0 0 0 1 0 0 1 1 1]\n",
      " [0 0 0 0 1 1 1 0 0 1]\n",
      " [1 1 1 1 0 1 0 0 1 1]]\n",
      "\n",
      "Scikit-learn TfidfVectorizer results:\n",
      "['and' 'are' 'bodies' 'celestial' 'is' 'moon' 'satellite' 'star' 'sun'\n",
      " 'the']\n",
      "[[0.         0.         0.         0.         1.28768207 0.\n",
      "  0.         1.69314718 1.28768207 1.        ]\n",
      " [0.         0.         0.         0.         1.28768207 1.28768207\n",
      "  1.69314718 0.         0.         1.        ]\n",
      " [1.69314718 1.69314718 1.69314718 1.69314718 0.         1.28768207\n",
      "  0.         0.         1.28768207 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary:\", vocab)\n",
    "print(\"\\nManual TF-IDF results:\")\n",
    "for i, doc in enumerate(manual_results):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    for word in vocab:\n",
    "        print(f\"{word}: {doc[word]:.4f}\", end=\" | \")\n",
    "    print()\n",
    "\n",
    "print(\"\\nScikit-learn CountVectorizer results:\")\n",
    "print(count_vec.get_feature_names_out())\n",
    "print(count_array)\n",
    "\n",
    "print(\"\\nScikit-learn TfidfVectorizer results:\")\n",
    "print(tfidf_vec.get_feature_names_out())\n",
    "print(tfidf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4dbc78-3fd1-41c3-9fe1-1c352456c19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9d55b4-353d-4f91-a433-3e3e71118889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
